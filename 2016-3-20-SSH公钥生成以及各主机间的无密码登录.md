# SSH公钥生成以及各主机间的无密码登录
注:[]为需替换的内容,master表示主机,slave表示从机
##原理
master要实现无密码公钥认证，连接到Salve上时，需要在master上生成一个密钥对，包括一个公钥和一个私钥，而后将公钥复制到所有的Slave上。当master通过SSH连接salve时，salve就会生成一个随机数并用Master的公钥对随机数进行加密，并发送给master。master收到加密数之后再用私钥解密，并将解密数回传给slave，slave确认解密数无误之后就允许master进行连接了。这就是一个公钥认证过程，其间不需要用户手工输入密码。
    
###实现master登录各台slave

####准备工作
master和slaves已经修改好主机名,并且hosts文件有对方的hosts的地址。
![](http://7xqhly.com1.z0.glb.clouddn.com/bbb.png)
####步骤
1.确保主机之间可以通过密码相互登录
例如root用户输入 ssh slave1 就是登录到slave1的root用户
假如需要登录到slave1的hadoop用户
所以确保各主机共有一个相同的账户,例如hadoop,登录时要切换到hadoop用户。
2.生成公钥
(1)在master下以hadoop用户生成公钥
ssh-keygen -t rsa -P ''
+ -P表示密码，-P '' 就表示空密码,这里没有输入。
+ 注意这里不是需要登录的主机的密码，只是使用公钥时需要输入的密码，因为实现的是全程无密码,所以这里没有输入。
+ 如果不输入公钥的名称,那么默认名称是id_rsa,且生成的公钥默认存放在"~/.ssh"目录下,输入名称则会保存到当前目录下。
+ 为什么加上-P?见可能遇到的问题
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopergreg.png)
最后显示的图形是公钥的指纹加密
(2)进入~/.ssh目录
cat id_rsa.pub >> authorized_keys 生成authorized_keys文件
并添加权限
chmod 600 authorized_keys
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopgergg.png)
(3)修改sshd_config文件
sudo vim /etc/ssh/sshd_config
修改一下选项
1.RSAAuthentication 启用 RSA 认证
2.PubkeyAuthentication  启用公钥私钥配对认证方式
3.AuthorizedKeysFile 公钥文件路径,这里不用改
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopgrth.png)

(4)用hadoop登录本机验证
ssh localhost
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopgegrgr.png)

(5)把公钥复制其他主机上
  scp ~/.ssh/id_rsa.pub [需登录主机的用户名]@[主机IP]:[目录]/
  由于对hosts作了相应的修改,所以可以用hosts中的名称代替主机IP
  详见云主机主机名修改
  scp  ~/.ssh/id_rsa.pub hadoop@slave1:~/.ssh/
  ![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopag.png)
    然后登录到发送文件的主机并修改主机上.ssh文件夹的权限
    ssh slave1
    chmod 700 ~/.ssh/
    ![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopaaa.png)
(6)把Master.Hadoop的公钥追加到slave1的授权文件"authorized_keys"中。使用下面命令
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
(7)用root用户修改sshd_config
su root
vim /etc/ssh/sshd_config
修改步骤和上面的相同,只不过登录了新的主机而已。
(8)登录验证
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopaaar.png)
已无需密码了,成功。
(9)重复以上步骤,实现登录到其他主机
chmod 700 ~/.ssh
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
su root
vim /etc/ssh/sshd_config
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopawera.png)

###实现各台slave登录master
和Master无密码登录所有slave原理一样，就是把slave的公钥追加到Master的".ssh"文件夹下的"authorized_keys"中，记得是追加（>>）。
先把master的hosts文件通过scp复制到各个slave 的指定文件夹下，然后登陆各个slave使用cp命令覆盖hosts文件。
请修改好每台slave的主机名,见《云主机主机名修改》
这样ssh登录的时候只需要输入主机名就可以了。
下面以slave1登录master为例
1.首先创建slave1的公钥和私钥，并把自己的公钥追加到"authorized_keys"文件中。用到的命令如下：
ssh-keygen -t dsa -P ''
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
2.用命令scp复制slave1的公钥id_dsa.pub复制到master的/home/hadoop/目录下，并追加到master的authorized_keys中。
scp ~/.ssh/id_dsa.pub hadoop@master:~/.ssh/
ssh master
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopsaagwe23.png)
其他的slave类似

这样就实现了master登录各台slave和各台slave登录master,最后记得把所有主机下的公钥pub删除,保证安全。
rm -r ~/.ssh/id_rsa.pub 

可能遇到的问题
为什么加上-P?
如果不加-P会提示输入密码
![](http://7xqhly.com1.z0.glb.clouddn.com/hadoopfe.png)

引用
《Hadoop平台搭建使用系列教程（7）- SSH无密码验证》
http://blog.csdn.net/lina791211/article/details/11818825
《Hadoop海量数据处理  技术详解与项目实战》
  



